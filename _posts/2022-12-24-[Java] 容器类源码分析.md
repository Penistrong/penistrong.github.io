---
layout:     post
title:      "[Java] 容器类源码分析-Map篇"
subtitle:   "继承Collection和Map的容器类源码一窥"
author:     Penistrong
date:       2022-12-24 10:49:32 +0800
categories: jekyll update
catalog:    true
mathjax:    false
katex:      true
tags:
    - Java
---

# Java容器类源码分析-Map篇

基于**JDK8**以后的的`src.zip`对常用的容器类源码进行简单剖析

## Map

### HashMap

HashMap采用类一个`Node`类型(实现了`Map.Entry`接口)的数组作为存放哈希表的基础数据结构，利用位运算(除留余数法的简化版，见[#第三节](#首先计算哈希地址))计算哈希地址，并且使用*拉链法*处理哈希冲突问题

#### 存储结构

- 不会被序列化的哈希表数组

  ```java
  transient Node<K,V>[] table;
  ```

- 数组的初始化大小为16，且必须为2的幂，这是为了使用哈希函数时提高效率

  ```java
    /* The default initial capacity - MUST be a power of two. */
    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16
  ```

- Node是一种单向链表节点结构，同时存储哈希值、键值对和下一个具有同义哈希的节点

  ```java
  static class Node<K,V> implements Map.Entry<K,V> {
      final int hash;
      final K key;
      V value;
      Node<K,V> next;

      Node(int hash, K key, V value, Node<K,V> next) {
          this.hash = hash;
          this.key = key;
          this.value = value;
          this.next = next;
      }

      public final K getKey()        { return key; }
      public final V getValue()      { return value; }
      public final String toString() { return key + "=" + value; }

      public final int hashCode() {
          return Objects.hashCode(key) ^ Objects.hashCode(value);
      }

      public final V setValue(V newValue) {
          V oldValue = value;
          value = newValue;
          return oldValue;
      }

      public final boolean equals(Object o) {
          if (o == this)
              return true;

          return o instanceof Map.Entry<?, ?> e
                  && Objects.equals(key, e.getKey())
                  && Objects.equals(value, e.getValue());
      }
  }
  ```

#### 键值对的存储流程

当调用`HashMap::put`时，会使用内建的`HashMap::putVal`函数

```java
public V put(K key, V value) { return putVal(hash(key), key, value, false, true); }

final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);
    else {
        Node<K,V> e; K k;
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
            e = p;
        else if (p instanceof TreeNode)
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        else {
            for (int binCount = 0; ; ++binCount) {
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);
                    break;
                }
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                p = e;
            }
        }
        if (e != null) { // existing mapping for key
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    ++modCount;
    if (++size > threshold)
        resize();
    afterNodeInsertion(evict);
    return null;
}
```

##### 首先计算哈希地址

存储键值对时，首先会使用`hash()`函数计算键的哈希值

```java
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

HashMap在存入键为null的K-V对时，会将该K-V对存放在哈希表中索引为0的桶里，否则会将**键的hashCode右移16位后再和其本身做异或**

在`hash()`函数的JavaDoc里可以看到这么做是为了减少哈希冲突，需要结合下面的散列操作一起理解

```java
if ((p = tab[i = (n - 1) & hash]) == null) { ... }
```

一般的哈希函数为除留余数法，除数为哈希表长度。假设当前哈希数组的容量为`n`，它被规定为2的幂次，常规的取余操作如下: 让`hash`去除$n=2^p$，在二进制下商就是`hash`右移$p-1$位，被右移出去的这$p-1$个数位组成的就是余数

因为除法操作被编译后其计算速度远不如位运算，为了提高效率HashMap用位运算代替取余操作: `n-1`在二进制下是一串连续的1，可以看作是二进制掩码，将`n-1`直接与`hash`相与，在二进制下相当于提取了`hash`的低$p-1$位作为余数

虽然位运算取余快捷，但是产生的哈希冲突会比较多，如果直接使用存入键的hashCode作为`hash`去取余，由于采用掩码操作，其高位信息相当于都被丢弃了。比如，当哈希数组初始容量为`n=16`，`n-1`即$(1111)_b$只会保留`hash`的低4位信息

hashCode为32位int类型，可能出现多个键的hashcode低`p-1`位完全相同而高位大相径庭的情况，但它们都被存在同一个索引的桶中，性能大幅降低

因此在对键初步取哈希值时，会将其hashCode的高位右移16位到int类型的低16位上，再和其本身进行**异或**得到最终的哈希值`hash`，这样高位信息和低位信息获得了混合，就可以减少散列冲突、增大哈希表的散列程度

##### 接着处理哈希冲突

获得哈希地址即键值对要被存放进的桶下标后

- 如果当前桶为空，则新建1个Node节点放入桶中

- 如果不为空，则在桶中已有节点的单向链表上进行顺序查找，对每个节点的key执行判等操作：使用`==`判断两者地址是否相同或者调用`equals`函数继续判断两个键是否相同

  ```java
  if (p.hash == hash &&
      ((k = p.key) == key || (key != null && key.equals(k))))
  ```

  1. 如果某个已有节点的key与要插入的newKey相同，则将已有节点的value更新为newValue
  2. 否则采用**尾插法**，新建一个节点追加到该桶中链表的尾部

> 从*JDK8*开始，插入桶中链表的操作从*JDK7*的**头插法**改成了尾插法，主要是为了防止对HashMap并发插入时，如果触发了[数组扩容](#扩容原理)，扩容时需要重新分配所有元素的哈希地址，可能会出现同一桶中链表里的两个节点互相指向对方导致死循环

#### 键值对的查找流程

1. 计算查找键的哈希地址，时间复杂度为$O(1)$
2. 在对应桶中的单向链表上执行顺序查找，时间复杂度为$O(N)$

假设表长为$M$，键值对总数`size`=$N$，在哈希表比较均匀的情况下，每个桶里链表的平均长度大约是$\frac{N}{M}$，查找的平均复杂度为$O(\frac{N}{M})$

#### 扩容原理

HashMap的内置构造函数为

```java
public HashMap(int initialCapacity, float loadFactor) {
    if (initialCapacity < 0)
        throw new IllegalArgumentException("Illegal initial capacity: " +
                                          initialCapacity);
    if (initialCapacity > MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;
    if (loadFactor <= 0 || Float.isNaN(loadFactor))
        throw new IllegalArgumentException("Illegal load factor: " +
                                          loadFactor);
    this.loadFactor = loadFactor;
    this.threshold = tableSizeFor(initialCapacity);
}
```

其他构造函数包括无参和单参的，其中`loadFactor`默认为`0.75f`，初始容量默认为`16`。HashMap允许传入一个不为2的幂次的初始容量，它会调用`tableSizeFor()`函数转换到距离最近的2的幂

| 参数 | 含义 |
| ---- | ---- |
| capacity | 数组容量，为2的幂次，默认为`16` |
| size | 实际存储的键值对数量，也就是对外暴露的`Map::size` |
| threshold | size到达该阈值时就会触发数组扩容，构造HashMap时会通过`tableSizeFor()`计算得到，每次执行`resize()`时以`newThr=(int)newCap * loadFactor`进行更新 |
| loadFactor | 装载因子，即哈希表能够装载的元素比例，默认为`0.75f` |

##### 计算扩容后新数组的容量与阈值

由哈希表的查找流程可知，为了使$O(N/M)$尽可能小，需要哈希表的容量$M$尽可能得大。所以HashMap为了兼顾时间与空间上的效率，采用动态扩容的方式，每当存储的键值对数量`size`超过阈值`threshold`后便执行`resize()`函数

```java
// resize()函数里，新哈希数组的容量及其阈值的计算部分如下
final Node<K,V>[] resize() {
    Node<K,V>[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap > 0) {
        if (oldCap >= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                  oldCap >= DEFAULT_INITIAL_CAPACITY)
            newThr = oldThr << 1; // double threshold
    }
    else if (oldThr > 0) // initial capacity was placed in threshold
        newCap = oldThr;
    else {               // zero initial threshold signifies using defaults
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    if (newThr == 0) {
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                  (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;

    ...
}
```

如果哈希数组的旧容量`oldCap`大于等于默认初始容量16，则每次扩容都是将原数组扩大到2倍，相应的，新阈值`newThr`也更新为旧阈值`oldThr`的2倍。在不超出最大容量上限`MaximumCapacity`的其他情况下，新阈值也可以通过`(int)newCap * loadFactor`得到

##### 对旧数组中每个桶中的节点再哈希

扩容后的数组容量和阈值计算完毕后，新建1个新的数组，并遍历旧数组的每个桶，对里面存在的节点执行rehash操作:

```java
// resize()函数里，rehash再哈希的处理部分如下
final Node<K,V>[] resize() {
    ...

    @SuppressWarnings({"rawtypes","unchecked"})
    Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;
    if (oldTab != null) {
        for (int j = 0; j < oldCap; ++j) {
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                if (e.next == null)
                    newTab[e.hash & (newCap - 1)] = e;
                else if (e instanceof TreeNode)
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else { // preserve order
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    do {
                        next = e.next;
                        if ((e.hash & oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}
```

1. 如果当前桶里的节点唯一，将节点存入对应的新桶中，地址为`hash & (newCap - 1)`

2. 如果当前桶里的链表存在，无需每次都使用新容量去计算散列地址，因为`newCap`=$2^{p+1}$刚好为`oldCap`=$2^{p}$的2倍，且它们都是2的幂，则`newCap - 1`刚好比`oldCap - 1`多出一个**第`p`位**(最低位从0开始)。对每个节点判断其键*hash*在二进制表示中第`p`位上的值(*采用位运算`e.hash & oldCap`即可*)：

    - 如果为0, `hash & (newCap - 1) == hash & (oldCap - 1)`，散列地址不变，插入临时低位链表中(`loHead`后面)

    - 如果为1, `hash & (newCap - 1) == hash & (oldCap - 1) + pow(2, p)`，而$2^{p}$的大小就是`oldCap`的值，因此其散列地址就是原散列地址`j`加上`oldCap`，插入临时高位链表中(`hiHead`后面)

    - 最后将低位链表放在散列地址不变的桶中`newTab[j] = loHead`, 高位链表放在原散列地址加上原数组容量的新桶中`newTab[j + oldCap] = hiHead`

    > 再散列的过程中都是采用**尾插**的方式将旧节点插入到新链表的尾部，这样可以保证节点原来的有序性不被破坏

#### 桶中链表转换红黑树

HashMap源码中还定义了如下变量

| 参数 | 默认值 | 含义 |
| ---- | ---- | ---- |
| TREEIFY_THRESHOLD | 8 | 桶中节点数超过该阈值后便将链表转换为红黑树(调用`treeifyBin()`) |
| UNTREEIFY_THRESHOLD | 6 | 扩容分桶时使用，原桶里的红黑树结构因为分桶导致节点数减小，小于该阈值后就将红黑树转换为链表(调用`untreeify()`) |
| MIN_TREEIFY_CAPACITY | 64 | `treeifyBin()`中的关键阈值，只有当数组容量`n`超过该阈值后后才会执行转换操作，否则只调用`resize()` |

默认的`TREEIFY_THRESHOLD`也说明里自*JDK8*之后，虽然处理哈希冲突时采用时间复杂度较高的尾插法，但是只要桶中节点数超过`8`且数组总容量超过`64`后就会将桶中链表转换为红黑树，所以尾插法对性能的影响也不算大

> 但是红黑树建树还是比较消耗性能的

### ConcurrentHashMap

### LinkedHashMap
